{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paromasoni/.pyenv/versions/3.8.2/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Transparency Reports \n",
    "\n",
    "I downloaded India-specific reports from [Twitter's transparency center](https://transparency.twitter.com/en/reports/countries/in.html), cleaned and compiled them in Excel into a database. These reports began in 2012, as a way for Twitter to be transparent about \"government requests that impact the public, whether through overt attempts at political censorship or by way of soliciting account data through information requests.‚Äù They include their rate of compliance to these requests and the number of users explicitly identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_requests = pd.read_csv('TwitterTransparencyReportIndia_RemovalRequests.csv')\n",
    "info_reports = pd.read_csv('TwitterTransparencyReportIndia_InformationReports.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time period</th>\n",
       "      <th>Legal demands: court orders</th>\n",
       "      <th>Other legal demands</th>\n",
       "      <th>Combined removal requests</th>\n",
       "      <th>% change</th>\n",
       "      <th>Court orders compliance rate</th>\n",
       "      <th>Other legal demands compliance rate</th>\n",
       "      <th>Combined compliance rate</th>\n",
       "      <th>Court orders accounts specified</th>\n",
       "      <th>Other legal demands accounts specified</th>\n",
       "      <th>Combined accounts specified</th>\n",
       "      <th>Combined accounts withheld</th>\n",
       "      <th>Combined tweets withheld</th>\n",
       "      <th>Court orders accounts TOS</th>\n",
       "      <th>Other legal demands accounts TOS</th>\n",
       "      <th>Combined accounts TOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July - December 2020</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6956</td>\n",
       "      <td>6,971</td>\n",
       "      <td>151.0</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>220</td>\n",
       "      <td>18908</td>\n",
       "      <td>19,128</td>\n",
       "      <td>60.0</td>\n",
       "      <td>598</td>\n",
       "      <td>2</td>\n",
       "      <td>1308</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January - June 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2,768</td>\n",
       "      <td>2,772</td>\n",
       "      <td>254.0</td>\n",
       "      <td>25</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>9</td>\n",
       "      <td>13,191</td>\n",
       "      <td>13,200</td>\n",
       "      <td>17.0</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>1,159</td>\n",
       "      <td>1,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July - December 2019</td>\n",
       "      <td>7.0</td>\n",
       "      <td>775</td>\n",
       "      <td>782</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>36.3</td>\n",
       "      <td>36.7</td>\n",
       "      <td>1,230</td>\n",
       "      <td>6,604</td>\n",
       "      <td>7,834</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1,481</td>\n",
       "      <td>4</td>\n",
       "      <td>988</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January - June 2019</td>\n",
       "      <td>8.0</td>\n",
       "      <td>496</td>\n",
       "      <td>504</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2,484</td>\n",
       "      <td>73.0</td>\n",
       "      <td>241</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>July - December 2018</td>\n",
       "      <td>10.0</td>\n",
       "      <td>657</td>\n",
       "      <td>667</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2,228</td>\n",
       "      <td>95.0</td>\n",
       "      <td>114</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time period  Legal demands: court orders Other legal demands  \\\n",
       "0  July - December 2020                         15.0                6956   \n",
       "1   January - June 2020                          4.0               2,768   \n",
       "2  July - December 2019                          7.0                 775   \n",
       "3   January - June 2019                          8.0                 496   \n",
       "4  July - December 2018                         10.0                 657   \n",
       "\n",
       "  Combined removal requests  % change Court orders compliance rate  \\\n",
       "0                     6,971     151.0                           73   \n",
       "1                     2,772     254.0                           25   \n",
       "2                       782      55.0                         85.7   \n",
       "3                       504     -24.0                            -   \n",
       "4                       667     171.0                            -   \n",
       "\n",
       "  Other legal demands compliance rate  Combined compliance rate  \\\n",
       "0                                   9                       9.0   \n",
       "1                                13.8                      13.9   \n",
       "2                                36.3                      36.7   \n",
       "3                                   -                       NaN   \n",
       "4                                   -                       NaN   \n",
       "\n",
       "  Court orders accounts specified Other legal demands accounts specified  \\\n",
       "0                             220                                  18908   \n",
       "1                               9                                 13,191   \n",
       "2                           1,230                                  6,604   \n",
       "3                               -                                      -   \n",
       "4                               -                                      -   \n",
       "\n",
       "  Combined accounts specified  Combined accounts withheld  \\\n",
       "0                      19,128                        60.0   \n",
       "1                      13,200                        17.0   \n",
       "2                       7,834                        16.0   \n",
       "3                       2,484                        73.0   \n",
       "4                       2,228                        95.0   \n",
       "\n",
       "  Combined tweets withheld Court orders accounts TOS  \\\n",
       "0                      598                         2   \n",
       "1                      377                         0   \n",
       "2                    1,481                         4   \n",
       "3                      241                         -   \n",
       "4                      114                         -   \n",
       "\n",
       "  Other legal demands accounts TOS Combined accounts TOS  \n",
       "0                             1308                  1310  \n",
       "1                            1,159                 1,159  \n",
       "2                              988                   992  \n",
       "3                                -                   578  \n",
       "4                                -                   320  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removal_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report</th>\n",
       "      <th>Information requests - Routine</th>\n",
       "      <th>Information requests - Emergency</th>\n",
       "      <th>Information requests - Combined</th>\n",
       "      <th>Compliance rate - Routine</th>\n",
       "      <th>Compliance rate - Emergency</th>\n",
       "      <th>Compliance rate - Combined</th>\n",
       "      <th>Accounts specified - Routine</th>\n",
       "      <th>Accounts specified - Emergency</th>\n",
       "      <th>Accounts specified - Combined</th>\n",
       "      <th>Preservation - Accounts</th>\n",
       "      <th>Preservation - Requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July - December 2020</td>\n",
       "      <td>3463</td>\n",
       "      <td>152</td>\n",
       "      <td>3615</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7508</td>\n",
       "      <td>254</td>\n",
       "      <td>7762</td>\n",
       "      <td>3877</td>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January - June 2020</td>\n",
       "      <td>2,367</td>\n",
       "      <td>246</td>\n",
       "      <td>2,613</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5,906</td>\n",
       "      <td>440</td>\n",
       "      <td>6,346</td>\n",
       "      <td>2,366</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July - December 2019</td>\n",
       "      <td>662</td>\n",
       "      <td>127</td>\n",
       "      <td>789</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2,683</td>\n",
       "      <td>190</td>\n",
       "      <td>2,873</td>\n",
       "      <td>1,028</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January - June 2019</td>\n",
       "      <td>395</td>\n",
       "      <td>79</td>\n",
       "      <td>474</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,162</td>\n",
       "      <td>106</td>\n",
       "      <td>1,268</td>\n",
       "      <td>145</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>July - December 2018</td>\n",
       "      <td>373</td>\n",
       "      <td>49</td>\n",
       "      <td>422</td>\n",
       "      <td>19</td>\n",
       "      <td>10.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>976</td>\n",
       "      <td>76</td>\n",
       "      <td>1,052</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Report Information requests - Routine  \\\n",
       "0  July - December 2020                           3463   \n",
       "1   January - June 2020                          2,367   \n",
       "2  July - December 2019                            662   \n",
       "3   January - June 2019                            395   \n",
       "4  July - December 2018                            373   \n",
       "\n",
       "  Information requests - Emergency Information requests - Combined  \\\n",
       "0                              152                            3615   \n",
       "1                              246                           2,613   \n",
       "2                              127                             789   \n",
       "3                               79                             474   \n",
       "4                               49                             422   \n",
       "\n",
       "  Compliance rate - Routine Compliance rate - Emergency  \\\n",
       "0                       0.6                         0.6   \n",
       "1                         1                         0.8   \n",
       "2                       1.8                         0.7   \n",
       "3                       5.3                         3.8   \n",
       "4                        19                        10.2   \n",
       "\n",
       "   Compliance rate - Combined Accounts specified - Routine  \\\n",
       "0                         0.6                         7508   \n",
       "1                         1.0                        5,906   \n",
       "2                         1.6                        2,683   \n",
       "3                         5.0                        1,162   \n",
       "4                        18.0                          976   \n",
       "\n",
       "  Accounts specified - Emergency Accounts specified - Combined  \\\n",
       "0                            254                          7762   \n",
       "1                            440                         6,346   \n",
       "2                            190                         2,873   \n",
       "3                            106                         1,268   \n",
       "4                             76                         1,052   \n",
       "\n",
       "  Preservation - Accounts Preservation - Requests  \n",
       "0                    3877                    1585  \n",
       "1                   2,366                     526  \n",
       "2                   1,028                     144  \n",
       "3                     145                      36  \n",
       "4                     100                      30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_reports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping from the Lumen Database \n",
    "\n",
    "The [Lumen Database](https://lumendatabase.org/) is an initiative by Harvard University's Berkman Klein Center. It collects and analyzes legal complaints and requests for removal of online materials across the world. I ran an advanced search to obtain results for all content removal requests made from the Indian government or its subsidiaries to Twitter. \n",
    "\n",
    "I first made a list of paginated search links, used Selenium to scrape basic information about each legal notice from the results page. Then I used selenium to click through each link. Most of the results contained PDF or Word files that had to be downloaded, so I pulled the URL for each of these. I then obtained research credentials in order to download them separately. \n",
    "\n",
    "The code for each step is below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\"https://lumendatabase.org/notices/search?utf8=%E2%9C%93&title=india+twitter&title-require-all=true&sort_by=\",\n",
    "        \"https://lumendatabase.org/notices/search?page=2&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=3&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         'https://lumendatabase.org/notices/search?page=4&sort_by=&title-require-all=true&title=india+twitter',\n",
    "         \"https://lumendatabase.org/notices/search?page=5&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "        \"https://lumendatabase.org/notices/search?page=6&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=7&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=8&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=9&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=10&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=11&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=12&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "         \"https://lumendatabase.org/notices/search?page=13&sort_by=&title-require-all=true&title=india+twitter\",\n",
    "        \"https://lumendatabase.org/notices/search?page=14&sort_by=&title-require-all=true&title=india+twitter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "\n",
    "for link in links:\n",
    "    driver.get(link)\n",
    "\n",
    "    results = driver.find_elements_by_tag_name('li')\n",
    "\n",
    "\n",
    "    for each in results:\n",
    "        titles = each.find_elements_by_class_name('title')\n",
    "\n",
    "        for eachtitle in titles:\n",
    "            url_long = eachtitle.find_elements_by_tag_name('a')\n",
    "            for eachu in url_long:\n",
    "                url = eachu.get_attribute('href')\n",
    "                title = eachu.text\n",
    "\n",
    "        metadata = each.find_elements_by_class_name('metadata')\n",
    "\n",
    "        for eachm in metadata:\n",
    "\n",
    "            date_rec = eachm.find_elements_by_class_name('date-received')\n",
    "            for eachd in date_rec: \n",
    "                date_long = (eachd.find_elements_by_tag_name('time'))\n",
    "                for each in date_long:\n",
    "                    date_received = (each.get_attribute('datetime'))\n",
    "\n",
    "            date_sub = eachm.find_elements_by_class_name('date-submitted')\n",
    "            for eachd in date_sub: \n",
    "                date_long2 = (eachd.find_elements_by_tag_name('time'))\n",
    "                for each in date_long2:\n",
    "                    date_submitted = (each.get_attribute('datetime'))\n",
    "\n",
    "            sender_receiver = eachm.find_elements_by_class_name('sender-receiver')\n",
    "            for eachs in sender_receiver: \n",
    "                sender_long = (eachs.find_elements_by_class_name('sender'))\n",
    "                for each in sender_long:\n",
    "                    sender = (each.text)\n",
    "                receiver_long = (eachs.find_elements_by_class_name('receiver'))\n",
    "                for each in receiver_long:\n",
    "                    receiver = (each.text)\n",
    "\n",
    "            excerpt_full = eachm.find_elements_by_class_name('excerpt')\n",
    "            for eache in excerpt_full:\n",
    "                excerpt = (eache.text)\n",
    "\n",
    "\n",
    "\n",
    "            request = {\n",
    "                    'url': url,\n",
    "                    'title_text': title,\n",
    "                    'date_received' : date_received,\n",
    "                    'sender': sender,\n",
    "                    'receiver': receiver,\n",
    "                    'date_submitted': date_submitted,\n",
    "                    'excerpt': excerpt\n",
    "            }\n",
    "\n",
    "            requests.append(request)\n",
    "\n",
    "noticedf = pd.DataFrame(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clicking through each notice URL to get the PDF URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = noticedf.url.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdflist = []\n",
    "\n",
    "for link in urls:\n",
    "    driver.get(link)\n",
    "\n",
    "    # driver.get(\"https://lumendatabase.org/notices/22220327\")\n",
    "\n",
    "    results = driver.find_elements_by_class_name('attachments')\n",
    "    # print (results)\n",
    "\n",
    "    for each in results:\n",
    "        docs = each.find_elements_by_class_name('document')\n",
    "        for eachdoc in docs:\n",
    "            hrefs = eachdoc.find_elements_by_tag_name('a')\n",
    "            for eachhref in hrefs:\n",
    "                if 'doc' in eachhref.get_attribute('href'):\n",
    "                    url = eachhref.get_attribute('href')\n",
    "                    name = link\n",
    "                    \n",
    "                    \n",
    "        pdfs = each.find_elements_by_class_name('pdf')\n",
    "        for eachpdf in pdfs:\n",
    "            hrefs = eachpdf.find_elements_by_tag_name('a')\n",
    "            for eachhref in hrefs:\n",
    "                 if 'pdf' in eachhref.get_attribute('href'):\n",
    "                    url = eachhref.get_attribute('href')\n",
    "                    name = link\n",
    "\n",
    "                    pdfordoc = {\n",
    "                        'pdf_url': url,\n",
    "                        'notice_url': name\n",
    "\n",
    "                        }\n",
    "\n",
    "                    pdflist.append(pdfordoc)\n",
    "\n",
    "pdfs = pd.DataFrame(pdflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the dataframe with PDF links to the first dataframe, and some basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumendf = df.merge(pdf_df, how='left', left_on='url', right_on='notice_url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumendf.date_received = pd.to_datetime(lumendf.date_received.str.extract(r'([\\d\\-]+)T'))\n",
    "lumendf.date_submitted = pd.to_datetime(lumendf.date_submitted.str.extract(r'([\\d\\-]+)T'))\n",
    "\n",
    "lumendf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lumendf.to_csv('all_lumen_notices_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the PDFs locally\n",
    "\n",
    "Please note: The research credentials in this code are no longer valid; to replicate, make a request with the Lumen database to obtain a researcher account. \n",
    "\n",
    "In the following step, I extract all the text from these PDFs and upload the completed file so it can be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdfs = lumendf.pdf_url.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('prefs',  {\n",
    "    \"plugins.always_open_pdf_externally\": True\n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://lumendatabase.org/\")\n",
    "\n",
    "signin = driver.find_element_by_xpath(\"/html/body/footer/div/div[2]/nav/span[5]/a\").click()\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/section/div/div[2]/form/div[1]/input\").send_keys(\"paroma.soni@columbia.edu\")\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/section/div/div[2]/form/div[2]/input\").send_keys(\"Lumen_Researcher_2021_PS\")\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/section/div/div[2]/form/div[3]/input\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in all_pdfs:\n",
    "#   driver = webdriver.Chrome(options=options)\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumendf = pd.read_csv('all_lumen_notices_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumendf['pdf_filename'] = lumendf.pdf_url.str.extract(r'original\\/([\\w\\W\\d]*.[pdfdocx])')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all downloaded PDFs matched the filename in their respective URLs. So I changed the directory to the folder with the PDFs, and used `ls` on the command line to obtain a list of the filenames, which I saved into an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumen_filelist = pd.read_excel('lumen_filelist.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumen_df.merge(lumen_filelist, how='left', left_on='pdf_filename', right_on='lumen_filelist').to_csv('lumen notices with pdf name.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then merged the two and saved it as a .csv file, manually going through it to correct the ones that were different. I then ran the PDFs which did _not_ contain searchable text into Adobe Acrobat's batch OCR tool, and saved those with an \"\\_OCR\" suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumen_filelist_OCR = lumen_filelist.replace(to_replace ='.pdf', value = '_OCR.pdf', regex = True)\n",
    "lumen_filelist_OCR = lumen_filelist_OCR.lumen_filelist.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "textfromfiles = []\n",
    "pagenum = -1 \n",
    "\n",
    "for eachfile in lumen_filelist_OCR:\n",
    "    try:\n",
    "        pdfFileObj = open(f'LumenOCR/{eachfile}', 'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        count = (pdfReader.numPages)\n",
    "\n",
    "        numlist = list(range(count))\n",
    "        textlist = []  \n",
    "\n",
    "        for num in numlist:\n",
    "            pageObj = pdfReader.getPage(num)\n",
    "\n",
    "            try:\n",
    "                text=(pageObj.extractText())\n",
    "                text=text.split(\",\")\n",
    "        #         text\n",
    "            except:\n",
    "                text=f'{eachfile} on page number {num+1} had an error.'\n",
    "\n",
    "            if num+1 == count:\n",
    "                textlist.append(text)\n",
    "            else:\n",
    "                text2 = text\n",
    "\n",
    "                textlist.append(text2)\n",
    "    except:\n",
    "        eachfile = 'not found'\n",
    "            \n",
    "    eachpdftext = {\n",
    "            'pdf_name': eachfile,\n",
    "#             'page_number': num+1,\n",
    "            'max_pages': count,\n",
    "            'text': textlist\n",
    "            \n",
    "        }\n",
    "        \n",
    "    textfromfiles.append(eachpdftext)\n",
    "        \n",
    "textfromfiles\n",
    "\n",
    "df2 = pd.DataFrame(textfromfiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the OCR successfully converting the scanned images into searchable text, PyPDF still returned several errors when trying to extract that text. Many of these files ‚Äì¬†both OCR and plain text ‚Äì¬†also contained multiple languages, including Hindi and Telegu, which text extraction libraries had difficulty identifying. \n",
    "\n",
    "I proceeded to manually copy paste and clean the text from these PDFs, adding them to the Excel file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>lumen_filelist</th>\n",
       "      <th>date_received</th>\n",
       "      <th>text_from_pdf</th>\n",
       "      <th>OCR_yn</th>\n",
       "      <th>relevant</th>\n",
       "      <th>num_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_India__Lumen_Notice_for_Notice___Takedown_Req...</td>\n",
       "      <td>_India__Lumen_Notice_for_Notice___Takedown_Req...</td>\n",
       "      <td>2018-05-15</td>\n",
       "      <td>Twitter Receipt of Complaint _________________...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0113609641.pdf</td>\n",
       "      <td>0113609641.pdf</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 09 May, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0113614419.pdf</td>\n",
       "      <td>0113614419.pdf</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 09 May, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 16 May, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05_May__2019_Twitter_TDR_on_as.pdf</td>\n",
       "      <td>05_May__2019_Twitter_TDR_on_as.pdf</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>ElectionCommissionofIndia\\nFile No. 491/Social...</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pdf_filename  \\\n",
       "0  _India__Lumen_Notice_for_Notice___Takedown_Req...   \n",
       "6                                     0113609641.pdf   \n",
       "7                                     0113614419.pdf   \n",
       "8                             05_16_19_ECI_Order.pdf   \n",
       "9                 05_May__2019_Twitter_TDR_on_as.pdf   \n",
       "\n",
       "                                      lumen_filelist date_received  \\\n",
       "0  _India__Lumen_Notice_for_Notice___Takedown_Req...    2018-05-15   \n",
       "6                                     0113609641.pdf    2019-05-09   \n",
       "7                                     0113614419.pdf    2019-05-09   \n",
       "8                             05_16_19_ECI_Order.pdf    2019-05-16   \n",
       "9                 05_May__2019_Twitter_TDR_on_as.pdf    2019-05-05   \n",
       "\n",
       "                                       text_from_pdf OCR_yn relevant  \\\n",
       "0  Twitter Receipt of Complaint _________________...    NaN        y   \n",
       "6  File No. 491/Social Media/2019 Dated: 09 May, ...    NaN        y   \n",
       "7  File No. 491/Social Media/2019 Dated: 09 May, ...    NaN        y   \n",
       "8  File No. 491/Social Media/2019 Dated: 16 May, ...    NaN        y   \n",
       "9  ElectionCommissionofIndia\\nFile No. 491/Social...      y        y   \n",
       "\n",
       "   num_tweets  \n",
       "0           2  \n",
       "6           9  \n",
       "7           1  \n",
       "8          36  \n",
       "9           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf = pd.read_excel('lumen_fulltext.xlsx')\n",
    "textdf.relevant = textdf.relevant.fillna('y')\n",
    "textdf = textdf[textdf.relevant == 'y']\n",
    "textdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the extracted text with the original Lumen database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lumendf.merge(textdf, how='right',left_on='pdf_filename', right_on='pdf_filename').drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['url', 'title_text', 'date_received_x', 'sender','receiver', 'date_submitted', 'pdf_url', 'lumen_filelist', 'text_from_pdf']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the Twitter URLs and adding them to the dataframe, as well as the number of tweets flagged in each legal notice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-77a23869b5da>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweetlist'] = df.text_from_pdf.apply(lambda txt: re.findall(\"https?://twitter.com[^\\s]*\", txt))\n"
     ]
    }
   ],
   "source": [
    "df['tweetlist'] = df.text_from_pdf.apply(lambda txt: re.findall(\"https?://twitter.com[^\\s]*\", txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-f63ed8024d54>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['num_of_tweets'] = tweetcount\n"
     ]
    }
   ],
   "source": [
    "tweetcount = []\n",
    "for each in (df.tweetlist):\n",
    "    tweetcount.append(len(each))\n",
    "\n",
    "df['num_of_tweets'] = tweetcount   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title_text</th>\n",
       "      <th>date_received_x</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date_submitted</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>lumen_filelist</th>\n",
       "      <th>text_from_pdf</th>\n",
       "      <th>tweetlist</th>\n",
       "      <th>num_of_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lumendatabase.org/notices/16562206</td>\n",
       "      <td>Legal Request to Twitter from India - Ministry...</td>\n",
       "      <td>2018-05-15</td>\n",
       "      <td>Ministry of Electro‚Ä¶</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>https://lumendatabase.org/file_uploads/files/4...</td>\n",
       "      <td>_India__Lumen_Notice_for_Notice___Takedown_Req...</td>\n",
       "      <td>Twitter Receipt of Complaint _________________...</td>\n",
       "      <td>[https://twitter.com/TheVoiceKashmir, https://...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lumendatabase.org/notices/16654365</td>\n",
       "      <td>Legal Request to Twitter from India - Ministry...</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>Ministry of Electro‚Ä¶</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>https://lumendatabase.org/file_uploads/files/4...</td>\n",
       "      <td>_India__Lumen_Notice_for_Notice___Takedown_Req...</td>\n",
       "      <td>Twitter Receipt of Complaint _________________...</td>\n",
       "      <td>[https://twitter.com/TheVoiceKashmir, https://...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lumendatabase.org/notices/18523843</td>\n",
       "      <td>Legal Request to Twitter from India - Election...</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>Election Commission‚Ä¶</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>https://lumendatabase.org/file_uploads/files/4...</td>\n",
       "      <td>0113609641.pdf</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 09 May, ...</td>\n",
       "      <td>[https://twitter.com/TarunAg79908414/status/11...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lumendatabase.org/notices/18523843</td>\n",
       "      <td>Legal Request to Twitter from India - Election...</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>Election Commission‚Ä¶</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>https://lumendatabase.org/file_uploads/files/4...</td>\n",
       "      <td>0113609641.pdf</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 09 May, ...</td>\n",
       "      <td>[https://twitter.com/TarunAg79908414/status/11...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lumendatabase.org/notices/18524111</td>\n",
       "      <td>Legal Request to Twitter from India - Election...</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>Election Commission‚Ä¶</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>https://lumendatabase.org/file_uploads/files/4...</td>\n",
       "      <td>0113614419.pdf</td>\n",
       "      <td>File No. 491/Social Media/2019 Dated: 09 May, ...</td>\n",
       "      <td>[https://twitter.com/IAm_Sanjaysri/status/1125...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          url  \\\n",
       "0  https://lumendatabase.org/notices/16562206   \n",
       "1  https://lumendatabase.org/notices/16654365   \n",
       "2  https://lumendatabase.org/notices/18523843   \n",
       "3  https://lumendatabase.org/notices/18523843   \n",
       "4  https://lumendatabase.org/notices/18524111   \n",
       "\n",
       "                                          title_text date_received_x  \\\n",
       "0  Legal Request to Twitter from India - Ministry...      2018-05-15   \n",
       "1  Legal Request to Twitter from India - Ministry...      2018-05-31   \n",
       "2  Legal Request to Twitter from India - Election...      2019-05-09   \n",
       "3  Legal Request to Twitter from India - Election...      2019-05-09   \n",
       "4  Legal Request to Twitter from India - Election...      2019-05-09   \n",
       "\n",
       "                 sender receiver date_submitted  \\\n",
       "0  Ministry of Electro‚Ä¶  Twitter     2018-05-24   \n",
       "1  Ministry of Electro‚Ä¶  Twitter     2018-06-07   \n",
       "2  Election Commission‚Ä¶  Twitter     2019-05-09   \n",
       "3  Election Commission‚Ä¶  Twitter     2019-05-09   \n",
       "4  Election Commission‚Ä¶  Twitter     2019-05-09   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0  https://lumendatabase.org/file_uploads/files/4...   \n",
       "1  https://lumendatabase.org/file_uploads/files/4...   \n",
       "2  https://lumendatabase.org/file_uploads/files/4...   \n",
       "3  https://lumendatabase.org/file_uploads/files/4...   \n",
       "4  https://lumendatabase.org/file_uploads/files/4...   \n",
       "\n",
       "                                      lumen_filelist  \\\n",
       "0  _India__Lumen_Notice_for_Notice___Takedown_Req...   \n",
       "1  _India__Lumen_Notice_for_Notice___Takedown_Req...   \n",
       "2                                     0113609641.pdf   \n",
       "3                                     0113609641.pdf   \n",
       "4                                     0113614419.pdf   \n",
       "\n",
       "                                       text_from_pdf  \\\n",
       "0  Twitter Receipt of Complaint _________________...   \n",
       "1  Twitter Receipt of Complaint _________________...   \n",
       "2  File No. 491/Social Media/2019 Dated: 09 May, ...   \n",
       "3  File No. 491/Social Media/2019 Dated: 09 May, ...   \n",
       "4  File No. 491/Social Media/2019 Dated: 09 May, ...   \n",
       "\n",
       "                                           tweetlist  num_of_tweets  \n",
       "0  [https://twitter.com/TheVoiceKashmir, https://...              2  \n",
       "1  [https://twitter.com/TheVoiceKashmir, https://...              2  \n",
       "2  [https://twitter.com/TarunAg79908414/status/11...              9  \n",
       "3  [https://twitter.com/TarunAg79908414/status/11...              9  \n",
       "4  [https://twitter.com/IAm_Sanjaysri/status/1125...              1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving it as a list of tweets as well, to use the Twitter API on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split_text'] = df.text_from_pdf.str.split(r'[ \\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoftweets = []\n",
    "for each in df.split_text:\n",
    "    for e in each:\n",
    "        if 'http' in e:\n",
    "            listoftweets.append(e)\n",
    "\n",
    "listoftweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweepy (Twitter API) to get Tweet and User Information\n",
    "I created an Excel sheet with the list of tweets above, as well as all the column names that I wanted to populate using Twitter API. I cleaned it into a dataframe I could use in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-33e752e87c8e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  alltweetslist['tweet_id'] = alltweetslist.tweetlist.str.extract(r'status/([\\d\\w\\W]+)$')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetlist</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/TheVoiceKashmir</td>\n",
       "      <td>TheVoiceKashmir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/NayeemDass</td>\n",
       "      <td>NayeemDass</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/TarunAg79908414/status/112...</td>\n",
       "      <td>TarunAg79908414</td>\n",
       "      <td>1125910215855968263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweetlist         username  \\\n",
       "0                https://twitter.com/TheVoiceKashmir  TheVoiceKashmir   \n",
       "1                     https://twitter.com/NayeemDass       NayeemDass   \n",
       "2  https://twitter.com/TarunAg79908414/status/112...  TarunAg79908414   \n",
       "\n",
       "              tweet_id  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2  1125910215855968263  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = pd.read_excel('tweet_text.xlsx')\n",
    "tweet_text['username'] = tweet_text.tweetlist.str.extract(r'twitter.com/([\\w\\d_]+)')\n",
    "alltweetslist = tweet_text[['tweetlist', 'username']]\n",
    "alltweetslist['tweet_id'] = alltweetslist.tweetlist.str.extract(r'status/([\\d\\w\\W]+)$')\n",
    "\n",
    "alltweetslist.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also used a pivot table in Excel to conver the original Lumen dataframe to include each Twitter URL in a separate row, so I could merge my list of tweets with their corresponding legal notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumen_links = pd.read_excel('lumen_with_twitter_links_perrow.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetlist</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url</th>\n",
       "      <th>date_received_x</th>\n",
       "      <th>lumen_filelist</th>\n",
       "      <th>num_of_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/TheVoiceKashmir</td>\n",
       "      <td>TheVoiceKashmir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://lumendatabase.org/notices/16562206</td>\n",
       "      <td>2018-05-15</td>\n",
       "      <td>_India__Lumen_Notice_for_Notice___Takedown_Req...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/TheVoiceKashmir</td>\n",
       "      <td>TheVoiceKashmir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://lumendatabase.org/notices/17135197</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>Copy_of_Lumen_India.pdf</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweetlist         username tweet_id  \\\n",
       "0  https://twitter.com/TheVoiceKashmir  TheVoiceKashmir      NaN   \n",
       "1  https://twitter.com/TheVoiceKashmir  TheVoiceKashmir      NaN   \n",
       "\n",
       "                                          url date_received_x  \\\n",
       "0  https://lumendatabase.org/notices/16562206      2018-05-15   \n",
       "1  https://lumendatabase.org/notices/17135197      2018-08-15   \n",
       "\n",
       "                                      lumen_filelist  num_of_tweets  \n",
       "0  _India__Lumen_Notice_for_Notice___Takedown_Req...            2.0  \n",
       "1                            Copy_of_Lumen_India.pdf            6.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets = alltweetslist.merge(lumen_links, how='left', left_on='tweetlist', right_on='tweetlist')\n",
    "all_tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Tweepy to first find information about each user, and then each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler #(access key, access key secret)\n",
    "\n",
    "#access token, access token secret\n",
    "auth.set_access_token #(access key, access key secret)\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userdf_list = []\n",
    "\n",
    "for each in tweet_text.username:\n",
    "#     print (each)\n",
    "\n",
    "    try:\n",
    "        user = api.get_user(each)\n",
    "        \n",
    "        user_name = user.name\n",
    "        screen_name = user.screen_name\n",
    "        user_desc = user.description\n",
    "        status_count = user.statuses_count\n",
    "        following_count = user.friends_count\n",
    "        followers_count = user.followers_count\n",
    "        \n",
    "        eachuser = {\n",
    "        'screen_name': user_name,\n",
    "        'twitter_handle': screen_name,\n",
    "        'user_desc': user_desc,\n",
    "       ' status_count': status_count,\n",
    "        'following_count': following_count,\n",
    "        'followers_count': followers_count,\n",
    "        'active_status': 'active'\n",
    "    }\n",
    "        \n",
    "    except tweepy.TweepError as e:\n",
    "        error = e\n",
    "         \n",
    "        eachuser = {\n",
    "        'twitter_handle': each,\n",
    "        'active_status': error,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    userdf_list.append(eachuser)\n",
    "    \n",
    "df_users = pd.DataFrame(userdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tweet_text = all_tweets.merge(df_users_final, how='left', left_on='username', right_on='twitter_handle').drop_duplicates()\n",
    "\n",
    "full_tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusdflist = []\n",
    "\n",
    "for each in full_tweet_text.tweet_id2[:600]:\n",
    "#     print (each)\n",
    "\n",
    "    try:\n",
    "        status = api.get_status(each, tweet_mode=\"extended\")\n",
    "        status_text = (status.full_text)\n",
    "        \n",
    "    except tweepy.TweepError as e:\n",
    "        status_text = e\n",
    "    \n",
    "    eachstatus = {\n",
    "        'tweet_id': each,\n",
    "        'tweet_text': status_text\n",
    "    }\n",
    "    \n",
    "    statusdflist.append(eachstatus)\n",
    "\n",
    "df_tweets = pd.DataFrame(statusdflist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = full_tweet_text.merge(df_tweets, how='left', left_on='tweet_id', \n",
    "                     right_on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discovered that Twitter‚Äôs compliance is country-specific, meaning that withheld tweets are still visible if the Twitter user changes their country to any other one. So I ran the above code once again ‚Äì this time changing my Twitter account's locaiton to the United States as my country. I then built a database of what those specific tweets looked like in India versus outside of India.\n",
    "\n",
    "The final database is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_excel('Final_all_tweets.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>flagged_twitter_url</th>\n",
       "      <th>flagged_tweet_id</th>\n",
       "      <th>username_handle</th>\n",
       "      <th>flagged_date</th>\n",
       "      <th>lumen_filename</th>\n",
       "      <th>lumen_url</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>status_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>active_status</th>\n",
       "      <th>tweet_id2</th>\n",
       "      <th>us_tweet_text</th>\n",
       "      <th>india_tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/AMIT_GUJJU/status/11285815...</td>\n",
       "      <td>1128581518295613441</td>\n",
       "      <td>AMIT_GUJJU</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amit Kumar</td>\n",
       "      <td>Passionate Follower of Politics, Public Policy...</td>\n",
       "      <td>71632.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>68101.0</td>\n",
       "      <td>active</td>\n",
       "      <td>1128581518295613441</td>\n",
       "      <td>Sources: mera exit poll\\nU.P.; 58\\nBihar; 16\\n...</td>\n",
       "      <td>This Tweet from @AMIT_GUJJU has been withheld ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://twitter.com/bk_chudasama/status/112859...</td>\n",
       "      <td>1128592137350713344</td>\n",
       "      <td>bk_chudasama</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ranjitsinh Chudasama</td>\n",
       "      <td>Convener Social Media BJP JAMNAGAR (Dist) Hono...</td>\n",
       "      <td>110136.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>14910.0</td>\n",
       "      <td>active</td>\n",
       "      <td>1128592137350713344</td>\n",
       "      <td>Code 144: No status found with that ID.</td>\n",
       "      <td>No status found with that ID (Code 144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://twitter.com/Dehaati_Indian/status/1128...</td>\n",
       "      <td>1128582379369426944</td>\n",
       "      <td>Dehaati_Indian</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CovidWorrior</td>\n",
       "      <td>‡§ï‡§ø‡§∏‡§æ‡§® ‡§™‡•Å‡§§‡•ç‡§∞, \\nDoctor by Profession.</td>\n",
       "      <td>20037.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>active</td>\n",
       "      <td>1128582379369426944</td>\n",
       "      <td>Code 144: No status found with that ID.</td>\n",
       "      <td>No status found with that ID (Code 144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://twitter.com/sunnydeolBJP/status/112859...</td>\n",
       "      <td>1128599916731781121</td>\n",
       "      <td>sunnydeolBJP</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>05_16_19_ECI_Order.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Code 63: User has been suspended.</td>\n",
       "      <td>1128599916731781121</td>\n",
       "      <td>Code 63: User has been suspended.</td>\n",
       "      <td>This Tweet from @mahindrbahubali has been with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://twitter.com/CA_keshavKumar/status/1128...</td>\n",
       "      <td>1128652376020094976</td>\n",
       "      <td>CA_keshavKumar</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>15_May__2019_Twitter_TDR_on_Restriction_of_Pub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Code 50: User not found.</td>\n",
       "      <td>1128652376020094976</td>\n",
       "      <td>Code 144: No status found with that ID.</td>\n",
       "      <td>No status found with that ID (Code 144)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                flagged_twitter_url  \\\n",
       "0           0  https://twitter.com/AMIT_GUJJU/status/11285815...   \n",
       "1           1  https://twitter.com/bk_chudasama/status/112859...   \n",
       "2           2  https://twitter.com/Dehaati_Indian/status/1128...   \n",
       "3           3  https://twitter.com/sunnydeolBJP/status/112859...   \n",
       "4           4  https://twitter.com/CA_keshavKumar/status/1128...   \n",
       "\n",
       "      flagged_tweet_id username_handle flagged_date  \\\n",
       "0  1128581518295613441      AMIT_GUJJU   2019-05-16   \n",
       "1  1128592137350713344    bk_chudasama   2019-05-16   \n",
       "2  1128582379369426944  Dehaati_Indian   2019-05-16   \n",
       "3  1128599916731781121    sunnydeolBJP   2019-05-16   \n",
       "4  1128652376020094976  CA_keshavKumar   2019-05-16   \n",
       "\n",
       "                                      lumen_filename lumen_url  \\\n",
       "0                             05_16_19_ECI_Order.pdf       NaN   \n",
       "1                             05_16_19_ECI_Order.pdf       NaN   \n",
       "2                             05_16_19_ECI_Order.pdf       NaN   \n",
       "3                             05_16_19_ECI_Order.pdf       NaN   \n",
       "4  15_May__2019_Twitter_TDR_on_Restriction_of_Pub...       NaN   \n",
       "\n",
       "            screen_name                                          user_desc  \\\n",
       "0            Amit Kumar  Passionate Follower of Politics, Public Policy...   \n",
       "1  Ranjitsinh Chudasama  Convener Social Media BJP JAMNAGAR (Dist) Hono...   \n",
       "2          CovidWorrior               ‡§ï‡§ø‡§∏‡§æ‡§® ‡§™‡•Å‡§§‡•ç‡§∞, \\nDoctor by Profession.   \n",
       "3                   NaN                                                NaN   \n",
       "4                   NaN                                                NaN   \n",
       "\n",
       "    status_count  following_count  followers_count  \\\n",
       "0        71632.0           1316.0          68101.0   \n",
       "1       110136.0            917.0          14910.0   \n",
       "2        20037.0            469.0           1014.0   \n",
       "3            NaN              NaN              NaN   \n",
       "4            NaN              NaN              NaN   \n",
       "\n",
       "                       active_status            tweet_id2  \\\n",
       "0                             active  1128581518295613441   \n",
       "1                             active  1128592137350713344   \n",
       "2                             active  1128582379369426944   \n",
       "3  Code 63: User has been suspended.  1128599916731781121   \n",
       "4           Code 50: User not found.  1128652376020094976   \n",
       "\n",
       "                                       us_tweet_text  \\\n",
       "0  Sources: mera exit poll\\nU.P.; 58\\nBihar; 16\\n...   \n",
       "1            Code 144: No status found with that ID.   \n",
       "2            Code 144: No status found with that ID.   \n",
       "3                  Code 63: User has been suspended.   \n",
       "4            Code 144: No status found with that ID.   \n",
       "\n",
       "                                    india_tweet_text  \n",
       "0  This Tweet from @AMIT_GUJJU has been withheld ...  \n",
       "1            No status found with that ID (Code 144)  \n",
       "2            No status found with that ID (Code 144)  \n",
       "3  This Tweet from @mahindrbahubali has been with...  \n",
       "4            No status found with that ID (Code 144)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning categories to available tweets\n",
    "Filtering out data without tweet text (including only accounts in the URL) and attributing categories based on commonly occurring and relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweettext = final_df[~(final_df.us_tweet_text.fillna('Code').str.contains('Code'))].sort_values(by='flagged_date', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df_tweettext.us_tweet_text.str.contains('kashmir|burhan|martyr|#freedom|azaadi|kasmir|‡§∂‡§π‡•Ä‡§¶', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('exit poll|EVM|election|vote|referendum', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('farmer|kisaan|farm', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('covid|corona|vaccine|vaccination|social distanc|PMCares|pandemic|#ModiMadeDisaster|‡§ï‡•ã‡§∞‡•ã‡§®‡§æ|‡§ï‡•Å‡§Ç‡§≠|‡§¨‡§®‡§æ‡§∞‡§∏|‡§∂‡•ç‡§Æ‡§∂‡§æ‡§®', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('CAA|NRC|citizenship amendment act|‡§∂‡§æ‡§π‡•Ä‡§®|‡§¨‡§æ‡§ó|shaheen|bagh', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('Muslim|Islam|Hindu extremist|sikh|terrorist|masjid|pakistan|hindutva|mosque|cow|ghaziabad|khalistan|‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('rape|Hathras|Manisha|valmiki|gay|justice|‡§π‡§æ‡§•‡§∞‡§∏|‡§Æ‡§®‡•Ä‡§∑‡§æ', case=False, na=False)),\n",
    "              (df_tweettext.us_tweet_text.str.contains('protest|slogan|naxal|democrat|riot|yogi|maoist|regime|imperialis|police|army|‡§ú‡§µ‡§æ‡§®', case=False, na=False)) \n",
    "             ]\n",
    "\n",
    "# sequential list of values to assign for each condition\n",
    "values = ['Kashmir','Election', 'Farmer Protests', 'COVID-19', 'CAA/NRC', 'Religious/Anti-National', 'Sexual Violence', 'Politics/Riots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweettext['category'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweettext ['is_modi'] = np.where(df_tweettext.us_tweet_text.str.contains('Modi|PM|BJP|RSS|Narendra|‡§Æ‡•ã‡§¶‡•Ä', case=False, na=False), True, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweettext.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
